{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gduncan2/CS445_OpticalFlowProj/blob/main/445FinalProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aPaBHcBau-ki"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping cupy as it is not installed.\n",
            "WARNING: Skipping cupy-cuda11x as it is not installed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in .\\.venv\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in .\\.venv\\lib\\site-packages (from opencv-python) (2.2.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: cupy-cuda12x in .\\.venv\\lib\\site-packages (13.4.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in .\\.venv\\lib\\site-packages (from cupy-cuda12x) (2.2.5)\n",
            "Requirement already satisfied: fastrlock>=0.5 in .\\.venv\\lib\\site-packages (from cupy-cuda12x) (0.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scipy in .\\.venv\\lib\\site-packages (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in .\\.venv\\lib\\site-packages (from scipy) (2.2.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in .\\.venv\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in .\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in .\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in .\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in .\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in .\\.venv\\lib\\site-packages (from matplotlib) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in .\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in .\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in .\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in .\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in .\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# %pip uninstall cupy cupy-cuda11x -y\n",
        "# %pip install cupy-cuda120\n",
        "\n",
        "# %pip install opencv-python\n",
        "# %pip install cupy-cuda12x\n",
        "# %pip install scipy\n",
        "# %pip install matplotlib\n",
        "\n",
        "import cv2\n",
        "import cupy as cp\n",
        "import cupyx.scipy.ndimage\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pBfrhnN5DuCA"
      },
      "outputs": [],
      "source": [
        "def play_video(video, fps):\n",
        "    while (video.isOpened()):\n",
        "        retval, frame = video.read()\n",
        "        if retval:\n",
        "            cv2.imshow(\"Video\", frame)\n",
        "            val = cv2.waitKey(int(1000/fps))\n",
        "            if val == 27:\n",
        "                break\n",
        "        else:\n",
        "            break\n",
        "    video.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def write_video(filename, frames, fps):\n",
        "    output = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'XVID'), fps, (frames[0].shape[1], frames[0].shape[0]), True)\n",
        "    for frame in frames:\n",
        "        output.write(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    output.release()\n",
        "\n",
        "def get_video_frames(video):\n",
        "    frames = []\n",
        "    while(video.isOpened()):\n",
        "        retval, frame = video.read()\n",
        "        if retval:\n",
        "            frames.append(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "        else:\n",
        "            break\n",
        "    return frames\n",
        "def save_half_frames(frames):\n",
        "    os.makedirs('./outputs/even_frames', exist_ok=True)\n",
        "    os.makedirs('./outputs/odd_frames', exist_ok=True)\n",
        "\n",
        "    even_frames = []\n",
        "    odd_frames = []\n",
        "\n",
        "    for i, frame in enumerate(frames):\n",
        "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            even_frames.append(frame)\n",
        "            cv2.imwrite(f\"./outputs/even_frames/frame_{i:04d}.png\", frame_bgr)\n",
        "        else:\n",
        "            odd_frames.append(frame)\n",
        "            cv2.imwrite(f\"./outputs/odd_frames/frame_{i:04d}.png\", frame_bgr)\n",
        "\n",
        "    print(f\"Saved {len(even_frames)} even frames and {len(odd_frames)} odd frames.\")\n",
        "def load_saved_frames(folder):\n",
        "    frame_files = sorted([f for f in os.listdir(folder) if f.endswith('.png')])\n",
        "    loaded_frames = []\n",
        "\n",
        "    for file in frame_files:\n",
        "        path = os.path.join(folder, file)\n",
        "        frame = cv2.imread(path)\n",
        "        if frame is not None:\n",
        "            loaded_frames.append(frame)\n",
        "\n",
        "    print(f\"Loaded {len(loaded_frames)} frames from '{folder}'\")\n",
        "    return loaded_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Uc64fSa0JyHH"
      },
      "outputs": [],
      "source": [
        "def get_frame_pairs(frames: np.ndarray):\n",
        "    return [(frames[i], frames[i + 1]) for i in range(0, len(frames), 2)]\n",
        "\n",
        "def process_window_lk(\n",
        "    window_size_x: int,\n",
        "    window_size_y: int,\n",
        "    start_x: int,\n",
        "    start_y: int,\n",
        "    frame_tplus1: np.ndarray,\n",
        "    frame_t: np.ndarray,\n",
        "    fps: float,\n",
        "    epsilon: float = 1e-4\n",
        ") -> cp.ndarray:\n",
        "    # Calculate the temporal derivative\n",
        "    # frame_t = cv2.cvtColor(frame_t, cv2.COLOR_BGR2RGB)\n",
        "    # frame_tplus1 = cv2.cvtColor(frame_tplus1, cv2.COLOR_BGR2RGB)\n",
        "    H, W, _ = frame_t.shape\n",
        "\n",
        "    delta_t = 1 / fps\n",
        "    # Patch extraction and GPU transfer\n",
        "    patch_t = cp.asarray(frame_t[start_y:start_y+window_size_y, start_x:start_x+window_size_x].astype(np.float32)) / 255\n",
        "    patch_t1 = cp.asarray(frame_tplus1[start_y:start_y+window_size_y, start_x:start_x+window_size_x].astype(np.float32)) / 255\n",
        "\n",
        "    # Convert to grayscale\n",
        "    patch_t_gray  = 0.2989 * patch_t[:,:,0] + 0.5870 * patch_t[:,:,1] + 0.1140 * patch_t[:,:,2]\n",
        "    patch_t1_gray = 0.2989 * patch_t1[:,:,0] + 0.5870 * patch_t1[:,:,1] + 0.1140 * patch_t1[:,:,2]\n",
        "\n",
        "    # Compute temporal derivative\n",
        "    # I_t = (patch_t1_gray - patch_t_gray) / delta_t\n",
        "    I_t = (patch_t1_gray - patch_t_gray)\n",
        "\n",
        "\n",
        "    # Placeholder for the spatial derivatives\n",
        "    I_x = cp.zeros((window_size_x, window_size_y), dtype=cp.float32)\n",
        "    I_y = cp.zeros((window_size_x, window_size_y), dtype=cp.float32)\n",
        "\n",
        "    if start_x + window_size_x > W or start_y + window_size_y > H:\n",
        "        return cp.zeros((2,1), dtype=cp.float32)\n",
        "\n",
        "    smoothed = cp.asarray(cv2.GaussianBlur(cp.asnumpy(patch_t_gray), (5, 5), sigmaX=1.0, sigmaY=1.0))\n",
        "    I_x = cp.asarray(cv2.Sobel(cp.asnumpy(smoothed), cv2.CV_32F, 1, 0, ksize=3) * 0.5) # ∂/∂x\n",
        "    I_y = cp.asarray(cv2.Sobel(cp.asnumpy(smoothed), cv2.CV_32F, 0, 1, ksize=3) * 0.5) # ∂/∂y\n",
        "\n",
        "    Ix = I_x.flatten()\n",
        "    Iy = I_y.flatten()\n",
        "    It = I_t.flatten()\n",
        "\n",
        "    # The system of equations would look like this\n",
        "    # [\n",
        "    #   [∑ I_x^2,   ∑ I_x I_y],\n",
        "    #   [∑ I_x I_y, ∑ I_y^2]\n",
        "    # ]\n",
        "\n",
        "    A00 = cp.sum(Ix * Ix)   # ∑ I_x^2\n",
        "    A01 = cp.sum(Ix * Iy)   # ∑ I_x I_y\n",
        "    A11 = cp.sum(Iy * Iy)   # ∑ I_y^2\n",
        "\n",
        "    B0 = -cp.sum(Ix * It)   # -∑ I_x I_t\n",
        "    B1 = -cp.sum(Iy * It)   # -∑ I_y I_t\n",
        "\n",
        "    A = cp.array([[A00, A01],\n",
        "                  [A01, A11]], dtype=cp.float32)\n",
        "    B = cp.array([B0, B1],      dtype=cp.float32).reshape(2,1)\n",
        "\n",
        "    # This is striaght from the video where we check how invertible the matrix is\n",
        "    # In other words whether the system of equations are well conditioned or not\n",
        "    # We can think of a system where there is hardly any change, like a patch of texture with no change\n",
        "    det = A00*A11 - A01*A01\n",
        "    if det > epsilon:\n",
        "        uv = cp.linalg.solve(A, B)   # 2×1\n",
        "    else:\n",
        "        uv = cp.zeros((2,1), dtype=cp.float32)\n",
        "    return uv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Sx7YBwlLJOA"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/MyDrive/CS445/FinalProj/subset_of_frames\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "kaRgyvl6Jz_2",
        "outputId": "36853adf-e3c6-488f-a3bd-ed26d711c2e1"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "No frames loaded — check your folder path or file naming.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m         frames.append(img_rgb)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frames) == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo frames loaded — check your folder path or file naming.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m fps = \u001b[32m24\u001b[39m\n\u001b[32m     13\u001b[39m window_w, window_h = \u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m\n",
            "\u001b[31mRuntimeError\u001b[39m: No frames loaded — check your folder path or file naming."
          ]
        }
      ],
      "source": [
        "folder = '/content/drive/MyDrive/CS445/FinalProj/'\n",
        "frame_files = sorted(glob.glob(folder + 'subset_of_frames/frame_*.png'))\n",
        "frames = []\n",
        "for f in frame_files:\n",
        "    img = cv2.imread(f)\n",
        "    if img is not None:\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(img_rgb)\n",
        "\n",
        "if len(frames) == 0:\n",
        "    raise RuntimeError(\"No frames loaded — check your folder path or file naming.\")\n",
        "fps = 24\n",
        "window_w, window_h = 100, 100\n",
        "\n",
        "frames = cp.array(frames)\n",
        "T = len(frames)\n",
        "H, W = frames[0].shape[:2]\n",
        "nY = H // window_h\n",
        "nX = W // window_w\n",
        "\n",
        "flows = cp.zeros((T - 1, nY, nX, 2), dtype=cp.float32)\n",
        "\n",
        "for t in range(T - 1):\n",
        "    ft, ftplus1 = frames[t], frames[t + 1]\n",
        "    for y in range(nY):\n",
        "        y0 = y * window_h\n",
        "        for x in range(nX):\n",
        "            x0 = x * window_w\n",
        "            uv = process_window_lk(window_w, window_h, start_x=x0, start_y=y0,\n",
        "                                   frame_tplus1=ftplus1, frame_t=ft, fps=fps)\n",
        "            flows[t, y, x, 0] = uv[0, 0]\n",
        "            flows[t, y, x, 1] = uv[1, 0]\n",
        "\n",
        "T, patch_y, patch_x, uv_shape = flows.shape\n",
        "print(cp.asnumpy(flows).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FQq6qn3Ov2Rk"
      },
      "outputs": [],
      "source": [
        "def gradients(frame):\n",
        "    grad_x = cp.zeros_like(frame)\n",
        "    grad_y = cp.zeros_like(frame)\n",
        "\n",
        "    grad_x[:, 1:-1] = frame[:, 2:] - frame[:, :-2]\n",
        "    grad_y[1:-1, :] = frame[2:, :] - frame[:-2, :]\n",
        "\n",
        "    return grad_x, grad_y\n",
        "\n",
        "def point_attentuation(R, maxCorners=100, qualityLevel=0.01, minDistance=10):\n",
        "    maxR = R.max()\n",
        "    thresh = qualityLevel * maxR\n",
        "\n",
        "    # 1. Non-Maximum Suppression\n",
        "    footprint = cp.ones((minDistance*2+1, minDistance*2+1), dtype=cp.bool_)\n",
        "    local_max = cupyx.scipy.ndimage.maximum_filter(R, footprint=footprint) == R\n",
        "\n",
        "    # 2. Apply threshold\n",
        "    mask = (R >= thresh) & local_max\n",
        "\n",
        "    # 3. Get (x,y) coords\n",
        "    ys, xs = cp.nonzero(mask)\n",
        "    points = cp.stack([xs, ys], axis=1)\n",
        "\n",
        "    # 4. Sort by R strength descending\n",
        "    scores = R[ys, xs]\n",
        "    sort_idx = cp.argsort(scores)[::-1]\n",
        "    points = points[sort_idx]\n",
        "\n",
        "    # 5. Take top maxCorners\n",
        "    if points.shape[0] > maxCorners:\n",
        "        points = points[:maxCorners]\n",
        "\n",
        "    return points\n",
        "\n",
        "\n",
        "\n",
        "def shi_tomansi_points(frame, winsize, numberpts = 100,  qualityLevel=0.01, minDistance=10):\n",
        "  Scores = []\n",
        "  grad_x, grad_y = gradients(frame)\n",
        "  Ixsqsum = (grad_x*grad_x)\n",
        "  Ixysum = (grad_x*grad_y)\n",
        "  Iysqsum = (grad_y*grad_y)\n",
        "\n",
        "  kern = cp.ones((winsize,winsize))\n",
        "  IXX = cupyx.scipy.ndimage.convolve(Ixsqsum, kern, mode = 'constant')\n",
        "  IXY = cupyx.scipy.ndimage.convolve(Ixysum, kern, mode = 'constant')\n",
        "  IYY = cupyx.scipy.ndimage.convolve(Iysqsum, kern, mode = 'constant')\n",
        "\n",
        "  trace = IXX + IYY\n",
        "  diff = IXX - IYY\n",
        "  sqrt_term = cp.sqrt((diff * 0.5)**2 + IXY**2)\n",
        "\n",
        "  eig1 = trace * 0.5 + sqrt_term\n",
        "  eig2 = trace * 0.5 - sqrt_term\n",
        "\n",
        "  R = cp.minimum(eig1, eig2)\n",
        "  return point_attentuation(R, maxCorners = numberpts, qualityLevel = qualityLevel , minDistance = minDistance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_8a-3ek9zU5z"
      },
      "outputs": [],
      "source": [
        "def computeAffineTransformation(start, dest):\n",
        "    N = len(start)\n",
        "    ones = cp.ones((N, 1), dtype=cp.float32)\n",
        "    s = cp.concatenate([start, ones], axis=1)\n",
        "    d = dest\n",
        "    M, _, _, _ = cp.linalg.lstsq(s, d, rcond=None)\n",
        "    M = M.T\n",
        "    return M\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I-xQ89AHwsUc"
      },
      "outputs": [],
      "source": [
        "def OpticalFlowFrameInterp(frame0,frame1):\n",
        "  h, w = frame0.shape[:2]\n",
        "  gray0 = cv2.cvtColor(frame0, cv2.COLOR_BGR2GRAY).astype(np.float32) / 255.0\n",
        "  gray_cp = cp.asarray(gray0)\n",
        "  keypoints = shi_tomansi_points(gray_cp, winsize=20, numberpts=1000)\n",
        "  points = []\n",
        "  flows = []\n",
        "  for pt in keypoints:\n",
        "      x, y = int(pt[0]), int(pt[1])\n",
        "      if 0 <= x < w and 0 <= y < h:\n",
        "          flow = flow = process_window_lk(30, 30, x, y, frame1, frame0, fps=24)\n",
        "\n",
        "          if not cp.isnan(flow).any():\n",
        "              dx, dy = flow[0].item(), flow[1].item()\n",
        "              points.append([x, y])\n",
        "              flows.append([dx, dy])\n",
        "  points = np.array(points)\n",
        "  flows = np.array(flows)\n",
        "\n",
        "  if len(points) < 10:\n",
        "      return cv2.addWeighted(frame0, 0.5, frame1, 0.5, 0)\n",
        "\n",
        "  grid_x, grid_y = np.meshgrid(np.arange(w), np.arange(h))\n",
        "  points_x = griddata(points, flows[:, 0], (grid_x, grid_y), method='linear', fill_value=0)\n",
        "  points_y = griddata(points, flows[:, 1], (grid_x, grid_y), method='linear', fill_value=0)\n",
        "\n",
        "  map_x_0 = (grid_x + 0.5 * points_x).astype(np.float32)\n",
        "  map_y_0 = (grid_y + 0.5 * points_y).astype(np.float32)\n",
        "\n",
        "  map_x_1 = (grid_x - 0.5 * points_x).astype(np.float32)\n",
        "  map_y_1 = (grid_y - 0.5 * points_y).astype(np.float32)\n",
        "\n",
        "  warp0 = cv2.remap(frame0, map_x_0, map_y_0, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
        "  warp1 = cv2.remap(frame1, map_x_1, map_y_1, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n",
        "\n",
        "  interpolated = cv2.addWeighted(warp0, 0.5, warp1, 0.5, 0)\n",
        "  return interpolated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFzakJeRFjzq",
        "outputId": "30ba88fa-796b-4b98-eeb2-38614033a415"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWritten output to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# interpolate_full_video(\"roadrunner.mp4\", \"newvid.avi\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43minterpolate_full_video\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedia/output_24_fps_nvenc_hevc.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhogwarts.avi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36minterpolate_full_video\u001b[39m\u001b[34m(input_path, output_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minterpolate_full_video\u001b[39m(input_path, output_path):\n\u001b[32m      2\u001b[39m     video = cv2.VideoCapture(input_path)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     frames = \u001b[43mget_video_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     fps = video.get(cv2.CAP_PROP_FPS)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOriginal frames: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(frames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mget_video_frames\u001b[39m\u001b[34m(video)\u001b[39m\n\u001b[32m     21\u001b[39m frames = []\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m(video.isOpened()):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     retval, frame = \u001b[43mvideo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m retval:\n\u001b[32m     25\u001b[39m         frames.append(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "def interpolate_full_video(input_path, output_path):\n",
        "    video = cv2.VideoCapture(input_path)\n",
        "    frames = get_video_frames(video)\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    print(f\"Original frames: {len(frames)}\")\n",
        "\n",
        "    high_fps_frames = []\n",
        "    for i in range(len(frames) - 1):\n",
        "        f0 = frames[i]\n",
        "        f1 = frames[i + 1]\n",
        "        high_fps_frames.append(f0)\n",
        "        f_interp = OpticalFlowFrameInterp(f0, f1)\n",
        "        high_fps_frames.append(f_interp)\n",
        "        print(f\"\\rPercent Done: {100 * i / len(frames):.2f}%\", end='', flush=True)\n",
        "    print(f\"\\rPercent Done: {100}%\", end='', flush=True)\n",
        "    high_fps_frames.append(frames[-1])\n",
        "    print(f\"\\nOutput frames: {len(high_fps_frames)}\")\n",
        "    write_video(output_path, high_fps_frames, fps * 2)\n",
        "    print(f\"Written output to {output_path}\")\n",
        "\n",
        "# interpolate_full_video(\"roadrunner.mp4\", \"newvid.avi\")\n",
        "interpolate_full_video(\"media/output_24_fps_nvenc_hevc.mp4\", \"hogwarts.avi\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def interp_pair(i, f0, f1):\n",
        "    return i, OpticalFlowFrameInterp(f0, f1)\n",
        "\n",
        "def interpolate_full_video_parallel(input_path, output_path, max_workers=4):\n",
        "    video   = cv2.VideoCapture(input_path)\n",
        "    frames  = get_video_frames(video)\n",
        "    fps     = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    pairs = [(i, frames[i], frames[i+1]) for i in range(len(frames)-1)]\n",
        "    high_fps_frames = []\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
        "        futures = [ex.submit(interp_pair, *p) for p in pairs]\n",
        "        results = [None]*(len(frames)-1)\n",
        "        ctr = 0\n",
        "        for fut in as_completed(futures):\n",
        "            i, f_interp = fut.result()\n",
        "            results[i] = f_interp\n",
        "            ctr += 1\n",
        "            print(f\"\\rPercent Done: {100 * ctr / len(frames):.2f}%\", end='', flush=True)\n",
        "\n",
        "    for i, f_interp in enumerate(results):\n",
        "        high_fps_frames.append(frames[i])\n",
        "        high_fps_frames.append(f_interp)\n",
        "    high_fps_frames.append(frames[-1])\n",
        "\n",
        "    write_video(output_path, high_fps_frames, fps*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "CUDARuntimeError",
          "evalue": "cudaErrorInvalidValue: invalid argument",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCUDARuntimeError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43minterpolate_full_video_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedia/output_24_fps_nvenc_hevc.mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhogwarts_parallel.avi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36minterpolate_full_video_parallel\u001b[39m\u001b[34m(input_path, output_path, max_workers)\u001b[39m\n\u001b[32m     16\u001b[39m ctr = \u001b[32m0\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     i, f_interp = \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     results[i] = f_interp\n\u001b[32m     20\u001b[39m     ctr += \u001b[32m1\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36minterp_pair\u001b[39m\u001b[34m(i, f0, f1)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minterp_pair\u001b[39m(i, f0, f1):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m i, \u001b[43mOpticalFlowFrameInterp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mOpticalFlowFrameInterp\u001b[39m\u001b[34m(frame0, frame1)\u001b[39m\n\u001b[32m      2\u001b[39m h, w = frame0.shape[:\u001b[32m2\u001b[39m]\n\u001b[32m      3\u001b[39m gray0 = cv2.cvtColor(frame0, cv2.COLOR_BGR2GRAY).astype(np.float32) / \u001b[32m255.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m gray_cp = \u001b[43mcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m keypoints = shi_tomansi_points(gray_cp, winsize=\u001b[32m20\u001b[39m, numberpts=\u001b[32m1000\u001b[39m)\n\u001b[32m      6\u001b[39m points = []\n",
            "\u001b[36mFile \u001b[39m\u001b[32md:\\local_dev\\flow2\\.venv\\Lib\\site-packages\\cupy\\_creation\\from_data.py:88\u001b[39m, in \u001b[36masarray\u001b[39m\u001b[34m(a, dtype, order, blocking)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masarray\u001b[39m(a, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, *, blocking=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     57\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Converts an object to array.\u001b[39;00m\n\u001b[32m     58\u001b[39m \n\u001b[32m     59\u001b[39m \u001b[33;03m    This is equivalent to ``array(a, dtype, copy=False, order=order)``.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     86\u001b[39m \n\u001b[32m     87\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mcupy\\\\_core\\\\core.pyx:2455\u001b[39m, in \u001b[36mcupy._core.core.array\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mcupy\\\\_core\\\\core.pyx:2482\u001b[39m, in \u001b[36mcupy._core.core.array\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mcupy\\\\_core\\\\core.pyx:2647\u001b[39m, in \u001b[36mcupy._core.core._array_default\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mcupy\\\\cuda\\\\memory.pyx:488\u001b[39m, in \u001b[36mcupy.cuda.memory.MemoryPointer.copy_from_host_async\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends\\\\cuda\\\\api\\\\runtime.pyx:607\u001b[39m, in \u001b[36mcupy_backends.cuda.api.runtime.memcpyAsync\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mcupy_backends\\\\cuda\\\\api\\\\runtime.pyx:146\u001b[39m, in \u001b[36mcupy_backends.cuda.api.runtime.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mCUDARuntimeError\u001b[39m: cudaErrorInvalidValue: invalid argument"
          ]
        }
      ],
      "source": [
        "interpolate_full_video_parallel(\"media/output_24_fps_nvenc_hevc.mp4\", \"hogwarts_parallel.avi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original %s, New frame generated %s 24.0 48.0\n"
          ]
        }
      ],
      "source": [
        "original   = cv2.VideoCapture(\"media/output_24_fps_nvenc_hevc.mp4\")\n",
        "new       = cv2.VideoCapture(\"hogwarts_parallel.avi\")\n",
        "fps = original.get(cv2.CAP_PROP_FPS)\n",
        "new_fps = new.get(cv2.CAP_PROP_FPS)\n",
        "print (\"Original %s, New frame generated %s\", fps, new_fps)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
